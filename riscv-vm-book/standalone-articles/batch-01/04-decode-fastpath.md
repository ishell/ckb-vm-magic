# 图 4-1 长文：取指与解码快路径，如何在确定性边界内拿到性能

## 摘要

共识 VM 的性能优化必须满足一个前提：不改变语义。图 4-1 展示的快路径（页内快速取指、解码缓存、MOP、Trace）本质上是“结构化优化”，不是“语义冒险”。

## 1. 取指快路径：为什么先看页边界

`decode_bits` 分两类路径：

- 非页尾：快速 `execute_load32`
- 页尾：分段 `load16`，必要时跨页补读

这不是微优化细节，而是正确性条件：

- 不跨页时走快路径降低开销
- 跨页时走稳路径避免边界读错

## 2. 解码缓存：命中率与语义稳定

`instructions_cache` 的价值是减少重复 decode，但它必须配套失效规则。

至少要确保：

- reset 后缓存清空
- 版本变化不复用旧缓存
- 代码语义变化时不读陈旧解码

缓存命中率永远不该优先于语义正确性。

## 3. MOP 融合：把模式压缩，不把语义压坏

MOP 的正确定义是“可证明等价的模式融合”。

每条融合规则都应回答三问：

1. 融合前后寄存器状态是否一致？
2. 融合前后内存副作用是否一致？
3. 融合前后 PC 前进是否一致？

三问不成立，融合就不是优化而是语义分叉源。

## 4. Trace 执行：解释器里的局部线程化

`TraceMachine` 的策略是缓存 basic block，并预绑定处理函数。收益来源：

- 减少重复 decode
- 减少分发开销
- 提高循环体路径稳定性

它不追求 JIT 式激进优化，而是以可审计为前提做局部加速。

## 5. Rust 与 ASM 的协同边界

在汇编路径中，`RET_SLOWPATH` 回退 Rust 执行是关键安全阀：

- 快路径负责吞吐
- 慢路径负责语义兜底

这使优化和正确性形成主从关系，而非相互竞争。

## 6. 性能评估的正确方式

不建议只看单指令 microbenchmark。更有效的是：

- 真实 workload 下的 cycles 总量
- opcode 结构分布
- MOP/Trace 命中率
- 后端差分一致性

没有一致性证明的性能收益，在共识系统里没有发布价值。

## 7. 审计清单（可直接执行）

- 快路径与慢路径是否覆盖同一语义空间
- 缓存失效是否与 reset/version 联动
- 融合规则是否有反例测试
- 跨页取指是否有专门边界向量

## 8. 与主文映射

- 对应章节：`第 4 章`
- 关键代码：`src/decoder.rs`, `src/machine/trace.rs`, `src/instructions/execute.rs`
- 关联附录：`附录 F`（审计模板）、`附录 H/I`（端到端案例）

## 9. 一针见血结论

在共识 VM 中，真正有价值的性能优化不是“跑得最猛”，而是“快且可证明”。

